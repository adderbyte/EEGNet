{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by, \n",
    "Sriram Ravindran, sriram@ucsd.edu\n",
    "\n",
    "Original paper - https://arxiv.org/abs/1611.08024\n",
    "\n",
    "Please reach out to me if you spot an error.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here's the description from the paper</p>\n",
    "<img src=\"EEGNet.png\" style=\"width: 700px; float:left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.5218\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (self.m, 64), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4*2*7, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.view(-1, 4*2*7)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = EEGNet().cuda(0)\n",
    "print net.forward(Variable(torch.from_numpy(np.expand_dims(X_train[0], 0)).cuda(0)))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate function returns values of different criteria like accuracy, precision etc. \n",
    "In case you face memory overflow issues, use batch size to control how many samples get evaluated at one time. Use a batch_size that is a factor of length of samples. This ensures that you won't miss any samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 100\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(len(X)/batch_size):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(X_train[s:e]).cuda(0))\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    inputs = Variable(torch.from_numpy(X).cuda(0))\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted))\n",
    "            recall = recall_score(Y, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random data\n",
    "\n",
    "##### Data format:\n",
    "Datatype - float32 (both X and Y) <br>\n",
    "X.shape - (#samples, 1, #timepoints,  #channels) <br>\n",
    "Y.shape - (#samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.random.rand(100, 1, 120, 64).astype('float32') # np.random.rand generates between [0, 1)\n",
    "y_train = np.round(np.random.rand(100).astype('float32')) # binary data, so we round it to 0 or 1.\n",
    "\n",
    "X_val = np.random.rand(100, 1, 120, 64).astype('float32')\n",
    "y_val = np.round(np.random.rand(100).astype('float32'))\n",
    "\n",
    "X_test = np.random.rand(100, 1, 120, 64).astype('float32')\n",
    "y_test = np.round(np.random.rand(100).astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.42032796144\n",
      "Train -  [0.63, 0.65355279004415889, 0.64077669902912615]\n",
      "Validation -  [0.53000000000000003, 0.55528355773153804, 0.50526315789473686]\n",
      "Test -  [0.51000000000000001, 0.51241987179487181, 0.52427184466019416]\n",
      "\n",
      "Epoch  1\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.31477499008\n",
      "Train -  [0.65000000000000002, 0.7551184263348053, 0.71999999999999997]\n",
      "Validation -  [0.5, 0.55365157078743366, 0.56896551724137934]\n",
      "Test -  [0.52000000000000002, 0.51482371794871795, 0.60655737704918034]\n",
      "\n",
      "Epoch  2\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.23936206102\n",
      "Train -  [0.70999999999999996, 0.82617422721798472, 0.7851851851851851]\n",
      "Validation -  [0.45000000000000001, 0.56589147286821695, 0.56692913385826771]\n",
      "Test -  [0.55000000000000004, 0.52564102564102555, 0.68085106382978722]\n",
      "\n",
      "Epoch  3\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.1783413291\n",
      "Train -  [0.68999999999999995, 0.86912886391007627, 0.77372262773722622]\n",
      "Validation -  [0.46000000000000002, 0.56956344349245203, 0.59090909090909094]\n",
      "Test -  [0.54000000000000004, 0.53205128205128205, 0.68918918918918914]\n",
      "\n",
      "Epoch  4\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.1258534193\n",
      "Train -  [0.70999999999999996, 0.89441991168205537, 0.7851851851851851]\n",
      "Validation -  [0.47999999999999998, 0.56915544675642593, 0.61194029850746268]\n",
      "Test -  [0.54000000000000004, 0.5296474358974359, 0.68918918918918914]\n",
      "\n",
      "Epoch  5\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.07600837946\n",
      "Train -  [0.72999999999999998, 0.91208350060216781, 0.79699248120300747]\n",
      "Validation -  [0.47999999999999998, 0.56385148918808659, 0.61194029850746268]\n",
      "Test -  [0.54000000000000004, 0.5232371794871794, 0.68918918918918914]\n",
      "\n",
      "Epoch  6\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.02643573284\n",
      "Train -  [0.76000000000000001, 0.92011240465676436, 0.8125]\n",
      "Validation -  [0.46999999999999997, 0.5614035087719299, 0.60150375939849621]\n",
      "Test -  [0.53000000000000003, 0.52083333333333337, 0.68027210884353739]\n",
      "\n",
      "Epoch  7\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.978446185589\n",
      "Train -  [0.79000000000000004, 0.92733841830590125, 0.83200000000000007]\n",
      "Validation -  [0.46000000000000002, 0.55569155446756424, 0.59090909090909094]\n",
      "Test -  [0.53000000000000003, 0.515625, 0.68027210884353739]\n",
      "\n",
      "Epoch  8\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.932614654303\n",
      "Train -  [0.82999999999999996, 0.93255720594138902, 0.85950413223140498]\n",
      "Validation -  [0.47999999999999998, 0.55446756425948596, 0.59999999999999998]\n",
      "Test -  [0.55000000000000004, 0.50440705128205132, 0.68531468531468531]\n",
      "\n",
      "Epoch  9\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.889044940472\n",
      "Train -  [0.81999999999999995, 0.93657165796868735, 0.84999999999999998]\n",
      "Validation -  [0.46000000000000002, 0.5479396164830681, 0.578125]\n",
      "Test -  [0.56000000000000005, 0.5, 0.6811594202898551]\n",
      "\n",
      "Epoch  10\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.846211701632\n",
      "Train -  [0.82999999999999996, 0.9397832195905258, 0.85714285714285721]\n",
      "Validation -  [0.45000000000000001, 0.54263565891472865, 0.56692913385826771]\n",
      "Test -  [0.55000000000000004, 0.48958333333333337, 0.66666666666666663]\n",
      "\n",
      "Epoch  11\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.804605096579\n",
      "Train -  [0.83999999999999997, 0.94098755519871524, 0.86440677966101698]\n",
      "Validation -  [0.45000000000000001, 0.53406772745818043, 0.56692913385826771]\n",
      "Test -  [0.54000000000000004, 0.47235576923076927, 0.65671641791044777]\n",
      "\n",
      "Epoch  12\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.763238012791\n",
      "Train -  [0.82999999999999996, 0.94098755519871524, 0.85470085470085466]\n",
      "Validation -  [0.46000000000000002, 0.52631578947368418, 0.57142857142857151]\n",
      "Test -  [0.54000000000000004, 0.46834935897435898, 0.65671641791044777]\n",
      "\n",
      "Epoch  13\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.72235929966\n",
      "Train -  [0.81999999999999995, 0.94339622641509435, 0.84482758620689657]\n",
      "Validation -  [0.46000000000000002, 0.52141982864137093, 0.57142857142857151]\n",
      "Test -  [0.55000000000000004, 0.46274038461538458, 0.66165413533834594]\n",
      "\n",
      "Epoch  14\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.68282520771\n",
      "Train -  [0.81999999999999995, 0.94138900040144524, 0.84482758620689657]\n",
      "Validation -  [0.46000000000000002, 0.51897184822521414, 0.57142857142857151]\n",
      "Test -  [0.56000000000000005, 0.46514423076923078, 0.66666666666666674]\n",
      "\n",
      "Epoch  15\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.644926339388\n",
      "Train -  [0.81000000000000005, 0.94018466479325569, 0.83760683760683763]\n",
      "Validation -  [0.45000000000000001, 0.5120359037127703, 0.56692913385826771]\n",
      "Test -  [0.54000000000000004, 0.46834935897435903, 0.65671641791044777]\n",
      "\n",
      "Epoch  16\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.60871553421\n",
      "Train -  [0.81000000000000005, 0.94058610999598558, 0.83760683760683763]\n",
      "Validation -  [0.44, 0.50346797225622197, 0.56923076923076921]\n",
      "Test -  [0.53000000000000003, 0.4727564102564103, 0.6518518518518519]\n",
      "\n",
      "Epoch  17\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.574794024229\n",
      "Train -  [0.81999999999999995, 0.94058610999598558, 0.84745762711864403]\n",
      "Validation -  [0.44, 0.5002039983680131, 0.56923076923076921]\n",
      "Test -  [0.53000000000000003, 0.47636217948717946, 0.6518518518518519]\n",
      "\n",
      "Epoch  18\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.543083459139\n",
      "Train -  [0.81999999999999995, 0.94098755519871546, 0.84745762711864403]\n",
      "Validation -  [0.44, 0.49122807017543868, 0.56923076923076921]\n",
      "Test -  [0.53000000000000003, 0.47435897435897434, 0.65693430656934315]\n",
      "\n",
      "Epoch  19\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.513958394527\n",
      "Train -  [0.81999999999999995, 0.93898032918506624, 0.84745762711864403]\n",
      "Validation -  [0.41999999999999998, 0.48470012239902088, 0.53968253968253965]\n",
      "Test -  [0.54000000000000004, 0.47636217948717952, 0.66176470588235303]\n",
      "\n",
      "Epoch  20\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.486722648144\n",
      "Train -  [0.81999999999999995, 0.9377759935768768, 0.84745762711864403]\n",
      "Validation -  [0.44, 0.48592411260709911, 0.54838709677419351]\n",
      "Test -  [0.55000000000000004, 0.47836538461538469, 0.66666666666666663]\n",
      "\n",
      "Epoch  21\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.460742250085\n",
      "Train -  [0.81000000000000005, 0.93576876756322769, 0.83760683760683763]\n",
      "Validation -  [0.44, 0.48592411260709911, 0.54838709677419351]\n",
      "Test -  [0.53000000000000003, 0.47956730769230771, 0.64661654135338353]\n",
      "\n",
      "Epoch  22\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.436065211892\n",
      "Train -  [0.81000000000000005, 0.93416298675230824, 0.83478260869565224]\n",
      "Validation -  [0.44, 0.48347613219094254, 0.54838709677419351]\n",
      "Test -  [0.53000000000000003, 0.48557692307692302, 0.64661654135338353]\n",
      "\n",
      "Epoch  23\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.412764549255\n",
      "Train -  [0.80000000000000004, 0.93416298675230824, 0.82456140350877194]\n",
      "Validation -  [0.45000000000000001, 0.48674010607915136, 0.55284552845528456]\n",
      "Test -  [0.53000000000000003, 0.49038461538461542, 0.64661654135338353]\n",
      "\n",
      "Epoch  24\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.390475213528\n",
      "Train -  [0.80000000000000004, 0.93376154154957847, 0.82456140350877194]\n",
      "Validation -  [0.45000000000000001, 0.48429212566299473, 0.54545454545454541]\n",
      "Test -  [0.51000000000000001, 0.49278846153846156, 0.62595419847328249]\n",
      "\n",
      "Epoch  25\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.369479030371\n",
      "Train -  [0.80000000000000004, 0.9329586511441188, 0.82456140350877194]\n",
      "Validation -  [0.44, 0.47939616483068137, 0.53333333333333321]\n",
      "Test -  [0.51000000000000001, 0.49439102564102561, 0.62595419847328249]\n",
      "\n",
      "Epoch  26\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.349496901035\n",
      "Train -  [0.79000000000000004, 0.93215576073865913, 0.81415929203539827]\n",
      "Validation -  [0.45000000000000001, 0.48388412892696853, 0.53781512605042014]\n",
      "Test -  [0.51000000000000001, 0.49198717948717946, 0.6201550387596898]\n",
      "\n",
      "Epoch  27\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.33028626442\n",
      "Train -  [0.79000000000000004, 0.93255720594138902, 0.81415929203539827]\n",
      "Validation -  [0.45000000000000001, 0.49041207670338638, 0.53781512605042014]\n",
      "Test -  [0.51000000000000001, 0.49278846153846156, 0.6201550387596898]\n",
      "\n",
      "Epoch  28\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.311946183443\n",
      "Train -  [0.79000000000000004, 0.93215576073865913, 0.81415929203539827]\n",
      "Validation -  [0.44, 0.49286005711954306, 0.53333333333333321]\n",
      "Test -  [0.51000000000000001, 0.49399038461538469, 0.6201550387596898]\n",
      "\n",
      "Epoch  29\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.294885396957\n",
      "Train -  [0.80000000000000004, 0.93215576073865913, 0.82456140350877194]\n",
      "Validation -  [0.44, 0.4944920440636475, 0.53333333333333321]\n",
      "Test -  [0.51000000000000001, 0.49278846153846156, 0.6201550387596898]\n",
      "\n",
      "Epoch  30\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.278855890036\n",
      "Train -  [0.80000000000000004, 0.93175431553592936, 0.82456140350877194]\n",
      "Validation -  [0.45000000000000001, 0.4940840473276214, 0.54545454545454541]\n",
      "Test -  [0.52000000000000002, 0.48717948717948717, 0.625]\n",
      "\n",
      "Epoch  31\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.263681739569\n",
      "Train -  [0.81000000000000005, 0.93135287033319969, 0.83478260869565224]\n",
      "Validation -  [0.45000000000000001, 0.49530803753569969, 0.54545454545454541]\n",
      "Test -  [0.51000000000000001, 0.48717948717948717, 0.6201550387596898]\n",
      "\n",
      "Epoch  32\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.249352358282\n",
      "Train -  [0.81000000000000005, 0.93175431553592947, 0.83478260869565224]\n",
      "Validation -  [0.46000000000000002, 0.49571603427172584, 0.54999999999999993]\n",
      "Test -  [0.51000000000000001, 0.48758012820512819, 0.6201550387596898]\n",
      "\n",
      "Epoch  33\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.236014589667\n",
      "Train -  [0.80000000000000004, 0.93135287033319969, 0.82456140350877194]\n",
      "Validation -  [0.46000000000000002, 0.49571603427172589, 0.54999999999999993]\n",
      "Test -  [0.5, 0.48677884615384615, 0.60937500000000011]\n",
      "\n",
      "Epoch  34\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.22343622148\n",
      "Train -  [0.80000000000000004, 0.9309514251304698, 0.82456140350877194]\n",
      "Validation -  [0.46000000000000002, 0.49653202774377808, 0.54999999999999993]\n",
      "Test -  [0.48999999999999999, 0.48317307692307687, 0.60465116279069753]\n",
      "\n",
      "Epoch  35\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.211665764451\n",
      "Train -  [0.80000000000000004, 0.93135287033319958, 0.82456140350877194]\n",
      "Validation -  [0.46000000000000002, 0.4940840473276214, 0.54999999999999993]\n",
      "Test -  [0.46999999999999997, 0.47756410256410259, 0.58267716535433078]\n",
      "\n",
      "Epoch  36\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.200554348528\n",
      "Train -  [0.80000000000000004, 0.9309514251304698, 0.82456140350877194]\n",
      "Validation -  [0.46999999999999997, 0.49204406364749087, 0.55462184873949583]\n",
      "Test -  [0.46000000000000002, 0.47796474358974361, 0.5714285714285714]\n",
      "\n",
      "Epoch  37\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.190041080117\n",
      "Train -  [0.80000000000000004, 0.9309514251304698, 0.82456140350877194]\n",
      "Validation -  [0.46999999999999997, 0.48918808649530804, 0.55462184873949583]\n",
      "Test -  [0.46000000000000002, 0.47756410256410253, 0.5714285714285714]\n",
      "\n",
      "Epoch  38\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.180205740035\n",
      "Train -  [0.80000000000000004, 0.93135287033319969, 0.82456140350877194]\n",
      "Validation -  [0.46000000000000002, 0.48959608323133419, 0.5423728813559322]\n",
      "Test -  [0.46999999999999997, 0.47596153846153844, 0.58267716535433078]\n",
      "\n",
      "Epoch  39\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.171016559005\n",
      "Train -  [0.80000000000000004, 0.93135287033319969, 0.82456140350877194]\n",
      "Validation -  [0.47999999999999998, 0.49041207670338632, 0.55172413793103448]\n",
      "Test -  [0.46000000000000002, 0.47636217948717952, 0.5714285714285714]\n",
      "\n",
      "Epoch  40\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.162421837449\n",
      "Train -  [0.80000000000000004, 0.93135287033319969, 0.82456140350877194]\n",
      "Validation -  [0.47999999999999998, 0.49163606691146472, 0.55172413793103448]\n",
      "Test -  [0.46000000000000002, 0.47235576923076927, 0.5714285714285714]\n",
      "\n",
      "Epoch  41\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.154305368662\n",
      "Train -  [0.80000000000000004, 0.93255720594138913, 0.82456140350877194]\n",
      "Validation -  [0.47999999999999998, 0.49000407996736023, 0.55172413793103448]\n",
      "Test -  [0.46000000000000002, 0.47075320512820512, 0.5714285714285714]\n",
      "\n",
      "Epoch  42\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.146676234901\n",
      "Train -  [0.80000000000000004, 0.93175431553592936, 0.82456140350877194]\n",
      "Validation -  [0.48999999999999999, 0.49041207670338632, 0.55652173913043468]\n",
      "Test -  [0.46000000000000002, 0.46754807692307698, 0.5714285714285714]\n",
      "\n",
      "Epoch  43\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.13959223032\n",
      "Train -  [0.80000000000000004, 0.93175431553592936, 0.82456140350877194]\n",
      "Validation -  [0.48999999999999999, 0.48837209302325579, 0.55652173913043468]\n",
      "Test -  [0.46000000000000002, 0.4671474358974359, 0.5714285714285714]\n",
      "\n",
      "Epoch  44\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.132951460779\n",
      "Train -  [0.80000000000000004, 0.9309514251304698, 0.82456140350877194]\n",
      "Validation -  [0.48999999999999999, 0.48959608323133413, 0.55652173913043468]\n",
      "Test -  [0.46000000000000002, 0.46434294871794873, 0.5714285714285714]\n",
      "\n",
      "Epoch  45\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.126698292792\n",
      "Train -  [0.80000000000000004, 0.9309514251304698, 0.82456140350877194]\n",
      "Validation -  [0.48999999999999999, 0.49082007343941242, 0.55652173913043468]\n",
      "Test -  [0.46000000000000002, 0.46554487179487181, 0.5714285714285714]\n",
      "\n",
      "Epoch  46\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.120813984424\n",
      "Train -  [0.80000000000000004, 0.9309514251304698, 0.82456140350877194]\n",
      "Validation -  [0.48999999999999999, 0.49530803753569969, 0.55652173913043468]\n",
      "Test -  [0.46000000000000002, 0.46394230769230771, 0.5714285714285714]\n",
      "\n",
      "Epoch  47\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.115325532854\n",
      "Train -  [0.80000000000000004, 0.93135287033319958, 0.82456140350877194]\n",
      "Validation -  [0.48999999999999999, 0.49734802121583027, 0.55652173913043468]\n",
      "Test -  [0.46000000000000002, 0.46634615384615385, 0.5714285714285714]\n",
      "\n",
      "Epoch  48\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.110207568854\n",
      "Train -  [0.80000000000000004, 0.93054997992773991, 0.82456140350877194]\n",
      "Validation -  [0.5, 0.49775601795185637, 0.56140350877192979]\n",
      "Test -  [0.46000000000000002, 0.46634615384615385, 0.5714285714285714]\n",
      "\n",
      "Epoch  49\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.105463989079\n",
      "Train -  [0.80000000000000004, 0.93014853472501013, 0.82456140350877194]\n",
      "Validation -  [0.5, 0.49653202774377803, 0.56140350877192979]\n",
      "Test -  [0.46000000000000002, 0.46554487179487181, 0.5714285714285714]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    print \"\\nEpoch \", epoch\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(len(X_train)/batch_size-1):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[s:e])\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "    print params\n",
    "    print \"Training Loss \", running_loss\n",
    "    print \"Train - \", evaluate(net, X_train, y_train, params)\n",
    "    print \"Validation - \", evaluate(net, X_val, y_val, params)\n",
    "    print \"Test - \", evaluate(net, X_test, y_test, params)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
